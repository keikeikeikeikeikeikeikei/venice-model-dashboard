<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Venice Model Pricing Dashboard</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;500;600;700&family=Inter:wght@400;500;600&display=swap');

        :root {
            /* Light Mode - Crisp & Airy */
            --bg-body: #f3f4f6;
            --text-main: #1f2937;
            --text-muted: #6b7280;
            --card-bg: #ffffff;
            --border-color: #e5e7eb;
            --primary: #6366f1;
            /* Indigo */
            --primary-gradient: linear-gradient(135deg, #6366f1 0%, #a855f7 100%);
            --secondary: #ec4899;
            --success: #10b981;
            --bar-bg: #e5e7eb;
            --header-bg: rgba(255, 255, 255, 0.8);
            --header-blur: 12px;
            --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
            --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            --radius-md: 12px;
            --radius-lg: 16px;
        }

        @media (prefers-color-scheme: dark) {
            :root {
                /* Dark Mode - Deep & Premium */
                --bg-body: #0f172a;
                /* Slate 900 */
                --text-main: #f3f4f6;
                --text-muted: #94a3b8;
                --card-bg: #1e293b;
                /* Slate 800 */
                --border-color: #334155;
                --primary: #818cf8;
                --primary-gradient: linear-gradient(135deg, #818cf8 0%, #c084fc 100%);
                --secondary: #f472b6;
                --success: #34d399;
                --bar-bg: #334155;
                --header-bg: rgba(30, 41, 59, 0.8);
                --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.3);
                --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.5);
            }
        }

        @media (max-width: 768px) {
            body { padding: 15px 8px; }
            h1 { font-size: 1.6rem; }
            .container { padding: 0; }
            .controls { padding: 15px; gap: 15px; }
            .main-controls { flex-direction: column; align-items: stretch; gap: 15px; }
            .search-box { max-width: none; }
            .filter-bar { gap: 10px; }
            .filter-group { flex-direction: row; align-items: center; gap: 8px; }
            .filter-group-label { min-width: 0; font-size: 0.6rem; opacity: 0.7; border-right: 1px solid var(--border-color); padding-right: 8px; margin-right: 2px; }
            .range-controls { flex-direction: column; align-items: stretch; gap: 20px; }
            .range-item { flex: 1; }
            .range-group div { flex-wrap: wrap; }
            .tab-btn { padding: 8px 12px; font-size: 0.85rem; flex: 1; text-align: center; }
        }

        * {
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', system-ui, sans-serif;
            background-color: var(--bg-body);
            color: var(--text-main);
            margin: 0;
            padding: 40px 20px;
            line-height: 1.6;
            transition: background-color 0.3s ease, color 0.3s ease;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        /* Header */
        header {
            margin-bottom: 40px;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        h1 {
            font-family: 'Outfit', sans-serif;
            font-weight: 700;
            font-size: 2.5rem;
            margin: 0;
            background: var(--primary-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            letter-spacing: -0.02em;
        }

        .meta {
            font-size: 0.95rem;
            color: var(--text-muted);
            font-weight: 500;
        }

        /* Controls Area */
        .controls {
            background: var(--card-bg);
            padding: 20px;
            border-radius: var(--radius-lg);
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-sm);
            margin-bottom: 30px;
            display: flex;
            flex-direction: column;
            gap: 20px;
            transition: box-shadow 0.3s ease;
        }

        .controls:hover {
            box-shadow: var(--shadow-md);
        }

        .main-controls {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            align-items: center;
            justify-content: space-between;
        }

        /* Tabs */
        .tabs {
            display: flex;
            background: var(--bg-body);
            padding: 4px;
            border-radius: 10px;
            gap: 4px;
        }

        .tab-btn {
            padding: 8px 24px;
            border: none;
            background: transparent;
            color: var(--text-muted);
            cursor: pointer;
            border-radius: 8px;
            font-weight: 600;
            font-family: 'Outfit', sans-serif;
            font-size: 0.95rem;
            transition: all 0.2s ease;
        }

        .tab-btn:hover {
            color: var(--text-main);
        }

        .tab-btn.active {
            background: var(--card-bg);
            color: var(--primary);
            box-shadow: var(--shadow-sm);
        }

        /* Filter Bar */
        .filter-bar {
            display: flex;
            flex-direction: column;
            gap: 16px;
            padding-top: 5px;
        }

        .filter-group {
            display: flex;
            align-items: center;
            gap: 12px;
            flex-wrap: wrap;
        }

        .filter-group-label {
            font-size: 0.75rem;
            font-weight: 700;
            text-transform: uppercase;
            color: var(--text-muted);
            min-width: 100px;
            letter-spacing: 0.05em;
        }

        .filter-item {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 0.9em;
            cursor: pointer;
            user-select: none;
            padding: 8px 16px;
            background: var(--bg-body);
            color: var(--text-main);
            border-radius: 30px;
            /* Pill shape */
            border: 1px solid transparent;
            transition: all 0.2s ease;
            font-weight: 500;
        }

        .filter-item:hover {
            background: var(--border-color);
        }

        /* Segmented Control Styling */
        .filter-segment {
            display: inline-flex;
            background: var(--bg-body);
            padding: 2px;
            border-radius: 10px;
            border: 1px solid var(--border-color);
            gap: 2px;
        }

        .filter-segment-item {
            padding: 6px 16px;
            font-size: 0.85rem;
            font-weight: 600;
            cursor: pointer;
            border-radius: 8px;
            color: var(--text-muted);
            transition: all 0.2s ease;
            user-select: none;
        }

        .filter-segment-item:hover {
            color: var(--text-main);
        }

        .filter-segment-item.active {
            background: var(--card-bg);
            color: var(--primary);
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1), 0 1px 2px rgba(0, 0, 0, 0.06);
            border: 1px solid var(--border-color);
            font-weight: 800;
        }

        .filter-item:has(input:checked) {
            background: var(--primary);
            border-color: var(--primary);
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .filter-item input:checked+span {
            color: white;
            font-weight: 700;
        }

        .range-controls {
            display: flex;
            gap: 24px;
            flex-wrap: wrap;
            align-items: flex-start;
            padding-top: 10px;
            border-top: 1px solid var(--border-color);
        }

        .range-group {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .range-item {
            display: flex;
            flex-direction: column;
            gap: 4px;
            font-size: 0.75rem;
            color: var(--text-muted);
            font-weight: 600;
        }

        .range-group select,
        .range-group input {
            padding: 8px 12px;
            border: 1px solid var(--border-color);
            border-radius: var(--radius-md);
            background: var(--bg-body);
            color: var(--text-main);
            font-family: inherit;
            font-size: 0.9rem;
            min-width: 140px;
            transition: border-color 0.2s, box-shadow 0.2s;
        }

        .range-group select:focus,
        .range-group input:focus {
            outline: none;
            border-color: var(--primary);
            box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
        }

        .ghost-btn {
            padding: 10px 14px;
            border-radius: var(--radius-md);
            border: 1px solid var(--border-color);
            background: transparent;
            color: var(--text-main);
            font-weight: 600;
            cursor: pointer;
            transition: border-color 0.2s, color 0.2s, box-shadow 0.2s;
        }

        .ghost-btn:hover {
            border-color: var(--primary);
            color: var(--primary);
            box-shadow: var(--shadow-sm);
        }

        /* Search Box */
        .search-box {
            flex-grow: 1;
            max-width: 400px;
            position: relative;
        }

        .search-box input {
            padding: 10px 16px;
            padding-left: 40px;
            /* Space for icon */
            border: 1px solid var(--border-color);
            border-radius: var(--radius-md);
            background: var(--bg-body);
            color: var(--text-main);
            width: 100%;
            font-family: inherit;
            font-size: 0.95rem;
            transition: border-color 0.2s, box-shadow 0.2s;
        }

        .search-box input:focus {
            outline: none;
            border-color: var(--primary);
            box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
        }

        /* Add search icon via CSS pseudo-element for simplicity without SVG clutter */
        .search-box::before {
            content: "üîç";
            position: absolute;
            left: 12px;
            top: 50%;
            transform: translateY(-50%);
            font-size: 1rem;
            opacity: 0.5;
            pointer-events: none;
        }

        /* Table */
        .table-container {
            overflow-x: auto;
            background: var(--card-bg);
            border-radius: var(--radius-lg);
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-md);
        }

        table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.95rem;
            min-width: 1000px;
        }

        th,
        td {
            padding: 16px 24px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }

        th {
            background: var(--header-bg);
            backdrop-filter: blur(var(--header-blur));
            -webkit-backdrop-filter: blur(var(--header-blur));
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.75rem;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            position: sticky;
            top: 0;
            z-index: 10;
            cursor: pointer;
            transition: color 0.2s;
        }

        th:hover {
            color: var(--primary);
        }

        tbody tr {
            transition: background-color 0.15s ease;
        }

        tbody tr:hover {
            background-color: rgba(99, 102, 241, 0.03);
            /* Very subtle primary tint */
        }

        tbody tr:last-child td {
            border-bottom: none;
        }

        /* Column Specifics */
        .model-name {
            font-family: 'Outfit', sans-serif;
            font-weight: 600;
            font-size: 1.05rem;
            color: var(--text-main);
            text-decoration: none;
            margin-bottom: 4px;
            display: inline-block;
        }

        .model-name:hover {
            color: var(--primary);
            text-decoration: none;
        }

        .model-id {
            font-family: 'ui-monospace', 'SFMono-Regular', 'Menlo', monospace;
            font-size: 0.75em;
            color: var(--text-muted);
            margin-bottom: 4px;
            opacity: 0.8;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .model-description {
            font-size: 0.8rem;
            color: var(--text-muted);
            margin-bottom: 8px;
            max-width: 450px;
            line-height: 1.4;
            display: -webkit-box;
            -webkit-line-clamp: 2;
            -webkit-box-orient: vertical;
            overflow: hidden;
            white-space: normal;
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .model-description.expanded {
            -webkit-line-clamp: unset;
            max-width: 600px;
            color: var(--text-main);
        }

        /* Tags */
        .tag-row {
            display: flex;
            gap: 6px;
            flex-wrap: wrap;
            margin-top: 4px;
        }

        .cap-badge {
            display: inline-flex;
            align-items: center;
            padding: 2px 8px;
            border-radius: 6px;
            background: var(--bg-body);
            border: 1px solid var(--border-color);
            font-size: 0.7em;
            font-weight: 600;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.03em;
        }

        .privacy-badge {
            font-size: 0.65rem;
            padding: 1px 6px;
            border-radius: 4px;
            font-weight: 700;
            text-transform: uppercase;
        }

        .privacy-private {
            background: rgba(16, 185, 129, 0.1);
            color: #10b981;
            border: 1px solid rgba(16, 185, 129, 0.2);
        }

        .privacy-anonymized {
            background: rgba(245, 158, 11, 0.1);
            color: #f59e0b;
            border: 1px solid rgba(245, 158, 11, 0.2);
        }

        .new-badge {
            background: var(--secondary);
            color: white;
            padding: 1px 6px;
            border-radius: 4px;
            font-size: 0.65rem;
            font-weight: 800;
            margin-left: 8px;
        }

        .beta-badge {
            background: #f59e0b; /* Amber */
            color: white;
            padding: 1px 6px;
            border-radius: 4px;
            font-size: 0.65rem;
            font-weight: 800;
            margin-left: 8px;
        }

        /* Price Bars */
        .price-cell {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        .price-val {
            font-weight: 600;
            font-feature-settings: "tnum";
            font-variant-numeric: tabular-nums;
        }

        .rel-bar-container {
            display: flex;
            align-items: center;
            gap: 10px;
            font-size: 0.75em;
            color: var(--text-muted);
        }

        /* Progress Bar */
        .rel-bar-container {
            width: 100%;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .rel-bar-bg {
            flex: 1;
            height: 6px;
            background: var(--bar-bg);
            border-radius: 3px;
            overflow: hidden;
        }

        .rel-bar-fill {
            height: 100%;
            width: 0%;
            border-radius: 3px;
            transition: width 0.5s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .bar-low {
            background: var(--success);
        }

        .bar-med {
            background: #f59e0b;
        }

        .bar-high {
            background: #ef4444;
        }

        /* Price Bridge */
        .price-bridge {
            display: flex;
            flex-direction: column;
            gap: 6px;
            min-width: 200px;
            padding: 4px 0;
        }

        .price-bridge-top {
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.85rem;
        }

        .price-value-group {
            display: flex;
            flex-direction: column;
            line-height: 1.2;
        }

        .price-value-label {
            font-size: 0.65rem;
            color: var(--text-muted);
            text-transform: uppercase;
            font-weight: 700;
        }

        .price-value-num {
            font-weight: 600;
            font-family: inherit;
        }

        .price-bridge-avg-info {
            text-align: center;
            flex: 1;
            font-weight: 800;
            color: var(--primary);
            font-size: 0.95rem;
        }

        th.col-combined-price {
            min-width: 220px;
        }

        .price-header-sort {
            font-size: 0.65rem;
            color: var(--text-muted);
            margin-top: 4px;
            display: flex;
            gap: 4px;
            justify-content: center;
        }

        .price-header-sort span {
            cursor: pointer;
            padding: 0 4px;
        }

        .price-header-sort span.active-sort {
            color: var(--primary);
            font-weight: 800;
            text-decoration: underline;
        }

        /* Feature Badges */
        .feature-tags {
            display: flex;
            gap: 6px;
            flex-wrap: wrap;
        }

        .feature-badge {
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.7rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.02em;
            border: 1px solid transparent;
        }

        /* Feature Colors */
        .feat-reasoning {
            background: rgba(139, 92, 246, 0.1);
            color: #8b5cf6;
            border-color: rgba(139, 92, 246, 0.2);
        }

        .feat-vision {
            background: rgba(16, 185, 129, 0.1);
            color: #10b981;
            border-color: rgba(16, 185, 129, 0.2);
        }

        .feat-func {
            background: rgba(245, 158, 11, 0.1);
            color: #f59e0b;
            border-color: rgba(245, 158, 11, 0.2);
        }

        .feat-code {
            background: rgba(59, 130, 246, 0.1);
            color: #3b82f6;
            border-color: rgba(59, 130, 246, 0.2);
        }

        .feat-search {
            background: rgba(236, 72, 153, 0.1);
            color: #ec4899;
            border-color: rgba(236, 72, 153, 0.2);
        }

        .feat-logprobs {
            background: rgba(107, 114, 128, 0.1);
            color: var(--text-muted);
            border-color: rgba(107, 114, 128, 0.2);
        }

        .feat-json {
            background: rgba(79, 70, 229, 0.1);
            color: #4f46e5;
            border-color: rgba(79, 70, 229, 0.2);
        }

        .feat-cache {
            background: rgba(16, 185, 129, 0.1);
            color: #10b981;
            border-color: rgba(16, 185, 129, 0.2);
        }

        /* Links */
        a {
            color: var(--primary);
            transition: color 0.2s;
        }

        a:hover {
            color: var(--secondary);
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        tbody tr {
            animation: fadeIn 0.3s ease-out forwards;
        }
    </style>
</head>

<body>

    <div class="container">
        <header>
            <h1>Venice Model Pricing</h1>
            <div class="meta">Generated from Live API Data (2026-02-28 12:53)</div>
        </header>

        <div class="controls">
            <div class="main-controls">
                <div class="tabs">
                    <button class="tab-btn active" onclick="switchTab('text')">Text</button>
                    <button class="tab-btn" onclick="switchTab('image')">Image</button>
                    <button class="tab-btn" onclick="switchTab('video')">Video</button>
                </div>
                <button class="ghost-btn" style="font-size: 0.7rem; padding: 4px 10px; align-self: flex-start; margin-top: -10px;" onclick="clearFilters()">üßπ Clear All Filters</button>

                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="Search (Refine by Name, ID, Source)..."
                        oninput="renderTable()">
                </div>
            </div>

            <div id="filterBar" class="filter-bar">
                <!-- Filters injected via JS -->
            </div>

            <div id="rangeControls" class="range-controls">
                <div class="range-group">
                    <label class="filter-group-label" style="min-width:0; margin-bottom:4px;">Constraints</label>
                    <div style="display:flex; gap:10px; flex-wrap:wrap;">
                        <div class="range-item">
                            <label for="minContext">Context min</label>
                            <select id="minContext" onchange="renderTable()">
                                <option value="0">Any</option>
                                <option value="32000">31k+</option>
                                <option value="128000">125k+</option>
                                <option value="160000">156k+</option>
                                <option value="198000">193k+</option>
                                <option value="256000">250k+</option>
                                <option value="400000">391k+</option>
                                <option value="1000000">977k+</option>
                            </select>
                        </div>
                        <div class="range-item">
                            <label for="maxAvgPrice">Max avg ($/1M)</label>
                            <input type="number" id="maxAvgPrice" min="0" step="0.01" placeholder="No limit"
                                oninput="renderTable()">
                        </div>
                    </div>
                </div>

                <div class="range-group">
                    <label class="filter-group-label" style="min-width:0; margin-bottom:4px;">Quick Sort</label>
                    <div style="display:flex; gap:8px; flex-wrap:wrap;">
                        <button class="ghost-btn" type="button" onclick="setCheapestSort()">üí∞ Cheapest</button>
                        <button class="ghost-btn" type="button" onclick="setNewestSort()">‚ú® Newest</button>
                        <button class="ghost-btn" type="button" onclick="setContextPriceSort()">üß† Context/Price</button>
                    </div>
                </div>
            </div>
        </div>

        <div class="table-container">
            <table>
                <thead id="tableHead">
                    <!-- Headers injected via JS -->
                </thead>
                <tbody id="tableBody">
                    <!-- Rows injected via JS -->
                </tbody>
            </table>
        </div>
    </div>

    <!-- Data Injection -->
    <script>
        window.veniceModels = {
  "text": [
    {
      "created": 1742262554,
      "id": "venice-uncensored",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.2,
            "diem": 0.2
          },
          "output": {
            "usd": 0.9,
            "diem": 0.9
          }
        },
        "availableContextTokens": 32000,
        "maxCompletionTokens": 4096,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp16",
          "supportsAudioInput": false,
          "supportsFunctionCalling": false,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Designed for maximum creative freedom and authentic interaction. Ideal for open-ended exploration, roleplay, and unfiltered dialogue. Features minimal content restrictions.",
        "name": "Venice Uncensored 1.1",
        "modelSource": "https://huggingface.co/cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition",
        "offline": false,
        "privacy": "private",
        "traits": [
          "most_uncensored"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1711929600,
      "id": "zai-org-glm-4.6",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.85,
            "diem": 0.85
          },
          "cache_input": {
            "usd": 0.3,
            "diem": 0.3
          },
          "output": {
            "usd": 2.75,
            "diem": 2.75
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 198000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp4",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "GLM-4.6 is a large language model developed by Zhiyuan AI, featuring strong reasoning capabilities and support for multiple languages. Supports the largest context window for processing extensive text and detailed analysis.",
        "name": "GLM 4.6",
        "modelSource": "https://huggingface.co/zai-org/GLM-4.6",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1770163200,
      "id": "olafangensan-glm-4.7-flash-heretic",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.14,
            "diem": 0.14
          },
          "output": {
            "usd": 0.8,
            "diem": 0.8
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 128000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "GLM-4.7-Flash-Heretic is an uncensored experimental variant of GLM-4.7-Flash, optimized for creative freedom and unfiltered dialogue with fast inference speed.",
        "name": "GLM 4.7 Flash Heretic",
        "modelSource": "https://huggingface.co/Olafangensan/GLM-4.7-Flash-heretic",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1769644800,
      "id": "zai-org-glm-4.7-flash",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.125,
            "diem": 0.125
          },
          "output": {
            "usd": 0.5,
            "diem": 0.5
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "GLM-4.7-Flash is a fast inference variant of GLM-4.7, optimized for speed while maintaining strong reasoning capabilities. Ideal for applications requiring quick responses with good quality.",
        "name": "GLM 4.7 Flash",
        "modelSource": "https://huggingface.co/zai-org/GLM-4.7-Flash",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1770768000,
      "id": "zai-org-glm-5",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 1,
            "diem": 1
          },
          "cache_input": {
            "usd": 0.2,
            "diem": 0.2
          },
          "output": {
            "usd": 3.2,
            "diem": 3.2
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 198000,
        "maxCompletionTokens": 32000,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "GLM-5 is the next-generation large language model developed by Zhiyuan AI, featuring significantly enhanced reasoning capabilities, improved instruction following, and support for multiple languages. Supports large context windows for processing extensive text and detailed analysis.",
        "name": "GLM 5",
        "modelSource": "https://huggingface.co/zai-org/GLM-5",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1766534400,
      "id": "zai-org-glm-4.7",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.55,
            "diem": 0.55
          },
          "cache_input": {
            "usd": 0.11,
            "diem": 0.11
          },
          "output": {
            "usd": 2.65,
            "diem": 2.65
          }
        },
        "availableContextTokens": 198000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp4",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "GLM-4.7 is a large language model developed by Zhiyuan AI, featuring strong reasoning capabilities and support for multiple languages. Supports the largest context window for processing extensive text and detailed analysis.",
        "name": "GLM 4.7",
        "modelSource": "https://huggingface.co/zai-org/GLM-4.7",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default",
          "most_intelligent",
          "function_calling_default"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-4b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.05,
            "diem": 0.05
          },
          "output": {
            "usd": 0.15,
            "diem": 0.15
          }
        },
        "availableContextTokens": 32000,
        "maxCompletionTokens": 4096,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "deprecation": {
          "date": "2026-03-29T00:00:00.000Z"
        },
        "description": "Optimized for speed and efficiency. Best for quick answers, simple queries, and lightweight tasks on mobile or low-latency connections.",
        "name": "Venice Small",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-4B",
        "offline": false,
        "privacy": "private",
        "traits": [
          "fastest"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1742262554,
      "id": "mistral-31-24b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.5,
            "diem": 0.5
          },
          "output": {
            "usd": 2,
            "diem": 2
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 4096,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "deprecation": {
          "date": "2026-03-29T00:00:00.000Z"
        },
        "description": "Balanced blend of speed and capability. Handles most everyday tasks with reliability, and supports image analysis. Ideal for general use with moderate complexity.",
        "name": "Venice Medium",
        "modelSource": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-235b-a22b-thinking-2507",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.45,
            "diem": 0.45
          },
          "output": {
            "usd": 3.5,
            "diem": 3.5
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Built for in-depth research and handling long, complex documents. Ideal for technical work, multimodal input, and high-precision tasks.",
        "name": "Qwen 3 235B A22B Thinking 2507",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default_reasoning"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-235b-a22b-instruct-2507",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.15,
            "diem": 0.15
          },
          "output": {
            "usd": 0.75,
            "diem": 0.75
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Built for in-depth research and handling long, complex documents. Ideal for technical work, multimodal input, and high-precision tasks.",
        "name": "Qwen 3 235B A22B Instruct 2507",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-next-80b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.35,
            "diem": 0.35
          },
          "output": {
            "usd": 1.9,
            "diem": 1.9
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp16",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Optimized for speed and efficiency.",
        "name": "Qwen 3 Next 80b",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-coder-480b-a35b-instruct",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.75,
            "diem": 0.75
          },
          "output": {
            "usd": 3,
            "diem": 3
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Optimized for code.",
        "name": "Qwen 3 Coder 480b",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default_code"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1758758400,
      "id": "hermes-3-llama-3.1-405b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 1.1,
            "diem": 1.1
          },
          "output": {
            "usd": 3,
            "diem": 3
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": false,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Hermes 3 405B is a frontier level, full parameter finetune of the Llama-3.1 405B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.",
        "name": "Hermes 3 Llama 3.1 405b",
        "modelSource": "https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-405B",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1762214400,
      "id": "google-gemma-3-27b-it",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.12,
            "diem": 0.12
          },
          "output": {
            "usd": 0.2,
            "diem": 0.2
          }
        },
        "availableContextTokens": 198000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to Gemma 2.",
        "name": "Google Gemma 3 27B Instruct",
        "modelSource": "https://huggingface.co/google/gemma-3-27b-it",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1764547200,
      "id": "grok-41-fast",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.25,
            "diem": 0.25
          },
          "cache_input": {
            "usd": 0.0625,
            "diem": 0.0625
          },
          "output": {
            "usd": 0.625,
            "diem": 0.625
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 1000000,
        "maxCompletionTokens": 30720,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Grok 4.1 Fast is xAI's best agentic tool-calling model that shines in real-world use cases like customer support and image analysis.",
        "name": "Grok 4.1 Fast",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1764633600,
      "id": "gemini-3-pro-preview",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 2.5,
            "diem": 2.5
          },
          "cache_input": {
            "usd": 0.625,
            "diem": 0.625
          },
          "output": {
            "usd": 15,
            "diem": 15
          }
        },
        "availableContextTokens": 198000,
        "maxCompletionTokens": 32768,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": true,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": true,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Gemini 3 Pro is Google flagship frontier model for high-precision multimodal reasoning with strong performance across text, image, and code.",
        "name": "Gemini 3 Pro Preview",
        "modelSource": "https://deepmind.google/models/gemini/pro/",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1771459200,
      "id": "gemini-3-1-pro-preview",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 2.5,
            "diem": 2.5
          },
          "cache_input": {
            "usd": 0.5,
            "diem": 0.5
          },
          "cache_write": {
            "usd": 0.5,
            "diem": 0.5
          },
          "output": {
            "usd": 15,
            "diem": 15
          },
          "extended": {
            "context_token_threshold": 200000,
            "input": {
              "usd": 5,
              "diem": 5
            },
            "output": {
              "usd": 22.5,
              "diem": 22.5
            },
            "cache_input": {
              "usd": 0.5,
              "diem": 0.5
            },
            "cache_write": {
              "usd": 0.5,
              "diem": 0.5
            }
          }
        },
        "availableContextTokens": 1000000,
        "maxCompletionTokens": 32768,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": true,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": true,
          "maxImages": 20,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": true,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Gemini 3.1 Pro is the latest evolution of Google flagship frontier model with 1M context, advancing high-precision multimodal reasoning across text, image, and code.",
        "name": "Gemini 3.1 Pro Preview",
        "modelSource": "https://deepmind.google/models/gemini/pro/",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1766102400,
      "id": "gemini-3-flash-preview",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.7,
            "diem": 0.7
          },
          "cache_input": {
            "usd": 0.07,
            "diem": 0.07
          },
          "output": {
            "usd": 3.75,
            "diem": 3.75
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": true,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": true,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Gemini 3 Flash Preview is a high speed, high value thinking model designed for agentic workflows, multi-turn chat, and coding assistance. It delivers near Pro level reasoning with substantially lower latency.",
        "name": "Gemini 3 Flash Preview",
        "modelSource": "https://deepmind.google/models/gemini/flash/",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1770249600,
      "id": "claude-opus-4-6",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 6,
            "diem": 6
          },
          "cache_input": {
            "usd": 0.6,
            "diem": 0.6
          },
          "cache_write": {
            "usd": 7.5,
            "diem": 7.5
          },
          "output": {
            "usd": 30,
            "diem": 30
          },
          "extended": {
            "context_token_threshold": 200000,
            "input": {
              "usd": 11,
              "diem": 11
            },
            "output": {
              "usd": 41.25,
              "diem": 41.25
            },
            "cache_input": {
              "usd": 1.1,
              "diem": 1.1
            },
            "cache_write": {
              "usd": 13.75,
              "diem": 13.75
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 1000000,
        "maxCompletionTokens": 128000,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Claude Opus 4.6 is Anthropic's most capable reasoning model, building on Opus 4.5 with enhanced performance across complex software engineering, agentic workflows, and long-horizon tasks. It features a 1M token context window, improved multimodal capabilities, and stronger robustness to prompt injection.",
        "name": "Claude Opus 4.6",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1764979200,
      "id": "claude-opus-4-5",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 6,
            "diem": 6
          },
          "cache_input": {
            "usd": 0.6,
            "diem": 0.6
          },
          "cache_write": {
            "usd": 7.5,
            "diem": 7.5
          },
          "output": {
            "usd": 30,
            "diem": 30
          }
        },
        "availableContextTokens": 198000,
        "maxCompletionTokens": 32768,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Claude Opus 4.5 is Anthropic's frontier reasoning model optimized for complex software engineering, agentic workflows, and long-horizon computer use. It offers strong multimodal capabilities, competitive performance across real-world coding and reasoning benchmarks, and improved robustness to prompt injection.",
        "name": "Claude Opus 4.5",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1771286400,
      "id": "claude-sonnet-4-6",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 3.6,
            "diem": 3.6
          },
          "cache_input": {
            "usd": 0.36,
            "diem": 0.36
          },
          "cache_write": {
            "usd": 4.5,
            "diem": 4.5
          },
          "output": {
            "usd": 18,
            "diem": 18
          },
          "extended": {
            "context_token_threshold": 200000,
            "input": {
              "usd": 7.2,
              "diem": 7.2
            },
            "output": {
              "usd": 27,
              "diem": 27
            },
            "cache_input": {
              "usd": 0.72,
              "diem": 0.72
            },
            "cache_write": {
              "usd": 9,
              "diem": 9
            }
          }
        },
        "availableContextTokens": 1000000,
        "maxCompletionTokens": 64000,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Claude Sonnet 4.6 is Anthropic's best combination of speed and intelligence, offering strong performance on coding, reasoning, and general tasks with excellent speed and cost efficiency. It features a 1M token context window and 64K max output tokens.",
        "name": "Claude Sonnet 4.6",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1736899200,
      "id": "claude-sonnet-4-5",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 3.75,
            "diem": 3.75
          },
          "cache_input": {
            "usd": 0.375,
            "diem": 0.375
          },
          "cache_write": {
            "usd": 4.69,
            "diem": 4.69
          },
          "output": {
            "usd": 18.75,
            "diem": 18.75
          }
        },
        "availableContextTokens": 198000,
        "maxCompletionTokens": 64000,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Claude Sonnet 4.5 is Anthropic's balanced model offering strong performance on coding, reasoning, and general tasks with good speed and cost efficiency.",
        "name": "Claude Sonnet 4.5",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1762387200,
      "id": "openai-gpt-oss-120b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.07,
            "diem": 0.07
          },
          "output": {
            "usd": 0.3,
            "diem": 0.3
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE) language model from OpenAI designed for high-reasoning, agentic, and general-purpose production use cases. The model supports configurable reasoning depth, full chain-of-thought access, and native tool use, including function calling, browsing, and structured output generation",
        "name": "OpenAI GPT OSS 120B",
        "modelSource": "https://huggingface.co/openai/gpt-oss-120b",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1765324800,
      "id": "kimi-k2-thinking",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.75,
            "diem": 0.75
          },
          "cache_input": {
            "usd": 0.375,
            "diem": 0.375
          },
          "output": {
            "usd": 3.2,
            "diem": 3.2
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "int4",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Kimi K2 Thinking is Moonshot AIs most advanced open reasoning model to date, extending the K2 series into agentic, long-horizon reasoning. Built on the trillion-parameter Mixture-of-Experts (MoE) architecture introduced in Kimi K2, it activates 32 billion parameters per forward pass and supports 256 k-token context windows.",
        "name": "Kimi K2 Thinking",
        "modelSource": "https://huggingface.co/moonshotai/Kimi-K2-Thinking",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1769548800,
      "id": "kimi-k2-5",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.75,
            "diem": 0.75
          },
          "cache_input": {
            "usd": 0.125,
            "diem": 0.125
          },
          "output": {
            "usd": 3.75,
            "diem": 3.75
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Kimi K2.5 is Moonshot AIs most advanced open reasoning model, featuring trillion-parameter Mixture-of-Experts architecture with 32B active parameters and 256K context windows.",
        "name": "Kimi K2.5",
        "modelSource": "",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1764806400,
      "id": "deepseek-v3.2",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.4,
            "diem": 0.4
          },
          "cache_input": {
            "usd": 0.2,
            "diem": 0.2
          },
          "output": {
            "usd": 1,
            "diem": 1
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 160000,
        "maxCompletionTokens": 32768,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": false,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "DeepSeek-V3.2 is an efficient large language model with DeepSeek Sparse Attention (DSA) for long contexts. It features strong reasoning and tool-use skills, achieving top results on the 2025 IMO and IOI.",
        "name": "DeepSeek V3.2",
        "modelSource": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1727966436,
      "id": "llama-3.2-3b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.15,
            "diem": 0.15
          },
          "output": {
            "usd": 0.6,
            "diem": 0.6
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 4096,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp16",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "name": "Llama 3.2 3B",
        "modelSource": "https://huggingface.co/meta-llama/Llama-3.2-3B",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1743897600,
      "id": "llama-3.3-70b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.7,
            "diem": 0.7
          },
          "output": {
            "usd": 2.8,
            "diem": 2.8
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 4096,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "name": "Llama 3.3 70B",
        "modelSource": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1765584000,
      "id": "openai-gpt-52",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 2.19,
            "diem": 2.19
          },
          "cache_input": {
            "usd": 0.219,
            "diem": 0.219
          },
          "output": {
            "usd": 17.5,
            "diem": 17.5
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "GPT-5.2 is the latest frontier-grade model in the GPT-5 series, offering stronger agentic and long context performance compared to GPT-5.1. It uses adaptive reasoning to allocate computation dynamically, responding quickly to simple queries while spending more depth on complex tasks.",
        "name": "GPT-5.2",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1736899200,
      "id": "openai-gpt-52-codex",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 2.19,
            "diem": 2.19
          },
          "cache_input": {
            "usd": 0.219,
            "diem": 0.219
          },
          "output": {
            "usd": 17.5,
            "diem": 17.5
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "GPT-5.2 Codex is OpenAI specialized coding model built on GPT-5.2, optimized for advanced software development, code generation, and technical problem-solving.",
        "name": "GPT-5.2 Codex",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1771891200,
      "id": "openai-gpt-53-codex",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 2.19,
            "diem": 2.19
          },
          "cache_input": {
            "usd": 0.219,
            "diem": 0.219
          },
          "output": {
            "usd": 17.5,
            "diem": 17.5
          }
        },
        "availableContextTokens": 400000,
        "maxCompletionTokens": 131072,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "GPT-5.3 Codex is OpenAI specialized coding model built on GPT-5.3, optimized for advanced software development, code generation, and technical problem-solving.",
        "name": "GPT-5.3 Codex",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1764547200,
      "id": "minimax-m21",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.4,
            "diem": 0.4
          },
          "cache_input": {
            "usd": 0.04,
            "diem": 0.04
          },
          "output": {
            "usd": 1.6,
            "diem": 1.6
          }
        },
        "availableContextTokens": 198000,
        "maxCompletionTokens": 32768,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "MiniMax-M2.1 is a lightweight, state-of-the-art large language model optimized for coding, agentic workflows, and modern application development.",
        "name": "MiniMax M2.1",
        "modelSource": "https://huggingface.co/MiniMaxAI/MiniMax-M2.1",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1770854400,
      "id": "minimax-m25",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.4,
            "diem": 0.4
          },
          "cache_input": {
            "usd": 0.04,
            "diem": 0.04
          },
          "output": {
            "usd": 1.6,
            "diem": 1.6
          }
        },
        "availableContextTokens": 198000,
        "maxCompletionTokens": 32768,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "MiniMax-M2.5 is a state-of-the-art large language model optimized for coding, agentic workflows, and modern application development with enhanced reasoning capabilities.",
        "name": "MiniMax M2.5",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1764547200,
      "id": "grok-code-fast-1",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.25,
            "diem": 0.25
          },
          "cache_input": {
            "usd": 0.03,
            "diem": 0.03
          },
          "output": {
            "usd": 1.87,
            "diem": 1.87
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Grok Code Fast 1 is a speedy and economical reasoning model that excels at agentic coding",
        "name": "Grok Code Fast 1",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1771977600,
      "id": "qwen3-5-35b-a3b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.3125,
            "diem": 0.3125
          },
          "cache_input": {
            "usd": 0.0625,
            "diem": 0.0625
          },
          "output": {
            "usd": 2.5,
            "diem": 2.5
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": true,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 1
          },
          "top_p": {
            "default": 0.95
          },
          "repetition_penalty": {
            "default": 1
          }
        },
        "description": "Qwen 3.5 35B A3B is a highly efficient MoE model with 35B total parameters and only 3B active parameters. It surpasses the larger Qwen3-235B-A22B while being 6.7x smaller, excelling at reasoning, coding, and general knowledge tasks.",
        "name": "Qwen 3.5 35B A3B",
        "modelSource": "",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1768521600,
      "id": "qwen3-vl-235b-a22b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.25,
            "diem": 0.25
          },
          "output": {
            "usd": 1.5,
            "diem": 1.5
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": true,
          "maxImages": 10,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "description": "Qwen3-VL 235B vision-language model with MoE architecture. The most powerful VL model in the Qwen series with superior visual perception, OCR, and multimodal reasoning.",
        "name": "Qwen3 VL 235B",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Instruct",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default_vision"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1769472000,
      "id": "qwen3-coder-480b-a35b-instruct-turbo",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.35,
            "diem": 0.35
          },
          "cache_input": {
            "usd": 0.04,
            "diem": 0.04
          },
          "output": {
            "usd": 1.5,
            "diem": 1.5
          }
        },
        "availableContextTokens": 256000,
        "maxCompletionTokens": 65536,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "Turbo variant of Qwen3 Coder 480B, optimized for faster inference on code tasks.",
        "name": "Qwen 3 Coder 480B Turbo",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1769472000,
      "id": "nvidia-nemotron-3-nano-30b-a3b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.075,
            "diem": 0.075
          },
          "output": {
            "usd": 0.3,
            "diem": 0.3
          }
        },
        "availableContextTokens": 128000,
        "maxCompletionTokens": 12288,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsMultipleImages": false,
          "supportsReasoning": false,
          "supportsReasoningEffort": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "description": "NVIDIA Nemotron 3 Nano 30B is a compact and efficient language model from NVIDIA, optimized for fast inference while maintaining strong performance across diverse tasks.",
        "name": "NVIDIA Nemotron 3 Nano 30B",
        "modelSource": "https://huggingface.co/nvidia/Nemotron-3-Nano-30B-A3B",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    }
  ],
  "image": [
    {
      "created": 1743099022,
      "id": "venice-sd35",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 25,
            "max": 30
          },
          "widthHeightDivisor": 16
        },
        "supportsWebSearch": false,
        "name": "Venice SD35",
        "modelSource": "https://huggingface.co/stabilityai/stable-diffusion-3.5-large",
        "offline": false,
        "privacy": "private",
        "traits": [
          "eliza-default"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1747080729,
      "id": "hidream",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "HiDream",
        "modelSource": "https://huggingface.co/HiDream-ai/HiDream-I1-Dev",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1764086377,
      "id": "flux-2-pro",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.04,
            "diem": 0.04
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 3000,
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "Flux 2 Pro",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1764086377,
      "id": "flux-2-max",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.09,
            "diem": 0.09
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "constraints": {
          "promptCharacterLimit": 3000,
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "Flux 2 Max",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1765986864,
      "id": "gpt-image-1-5",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.23,
            "diem": 0.23
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 32768,
          "aspectRatios": [
            "1:1",
            "3:2",
            "2:3"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "GPT Image 1.5",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1769437800,
      "id": "imagineart-1.5-pro",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.05,
            "diem": 0.05
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 10000,
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "ImagineArt 1.5 Pro",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1772064000,
      "id": "nano-banana-2",
      "model_spec": {
        "pricing": {
          "resolutions": {
            "1K": {
              "usd": 0.08,
              "diem": 0.08
            },
            "2K": {
              "usd": 0.16,
              "diem": 0.16
            },
            "4K": {
              "usd": 0.32,
              "diem": 0.32
            }
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "constraints": {
          "promptCharacterLimit": 32768,
          "defaultResolution": "1K",
          "resolutions": [
            "1K",
            "2K",
            "4K"
          ],
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": true,
        "name": "Nano Banana 2",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1763653951,
      "id": "nano-banana-pro",
      "model_spec": {
        "pricing": {
          "resolutions": {
            "1K": {
              "usd": 0.18,
              "diem": 0.18
            },
            "2K": {
              "usd": 0.24,
              "diem": 0.24
            },
            "4K": {
              "usd": 0.35,
              "diem": 0.35
            }
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "constraints": {
          "promptCharacterLimit": 32768,
          "defaultResolution": "1K",
          "resolutions": [
            "1K",
            "2K",
            "4K"
          ],
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": true,
        "name": "Nano Banana Pro",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1770854400,
      "id": "recraft-v4",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.06,
            "diem": 0.06
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 10000,
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "Recraft V4",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1770854400,
      "id": "recraft-v4-pro",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.29,
            "diem": 0.29
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 10000,
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "Recraft V4 Pro",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1762383600,
      "id": "seedream-v4",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.05,
            "diem": 0.05
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 10000,
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "SeedreamV4.5",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1771804800,
      "id": "seedream-v5-lite",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.05,
            "diem": 0.05
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 10000,
          "aspectRatios": [
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "defaultAspectRatio": "1:1",
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "SeedreamV5 Lite",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1738704152,
      "id": "lustify-sdxl",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Lustify SDXL",
        "modelSource": "https://civitai.com/models/573152/lustify-sdxl-nsfw-checkpoint",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1736635129,
      "id": "lustify-v7",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Lustify v7",
        "modelSource": "https://civitai.com/models/573152/lustify-sdxl-nsfw-checkpoint",
        "offline": false,
        "privacy": "private",
        "traits": [
          "most_uncensored"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1736635129,
      "id": "qwen-image",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 8,
            "max": 8
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Qwen Image",
        "modelSource": "https://huggingface.co/Qwen/Qwen-Image",
        "offline": false,
        "privacy": "private",
        "traits": [
          "highest_quality"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1736635129,
      "id": "wai-Illustrious",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 25,
            "max": 30
          },
          "widthHeightDivisor": 16
        },
        "supportsWebSearch": false,
        "name": "Anime (WAI)",
        "modelSource": "https://civitai.com/models/827184?modelVersionId=1761560",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1764758779,
      "id": "z-image-turbo",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "constraints": {
          "promptCharacterLimit": 7500,
          "steps": {
            "default": 8,
            "max": 8
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Z-Image Turbo",
        "modelSource": "https://huggingface.co/Tongyi-MAI/Z-Image-Turbo",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default",
          "fastest"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1769731200,
      "id": "chroma",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "model_sets": [
          "venice_recommendations"
        ],
        "constraints": {
          "promptCharacterLimit": 7500,
          "steps": {
            "default": 10,
            "max": 10
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Chroma",
        "modelSource": "https://huggingface.co/lodestones/Chroma1-HD",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1772064000,
      "id": "bria-bg-remover",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.018,
            "diem": 0.018
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "Background Remover",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    }
  ],
  "video": [
    {
      "created": 1765843200,
      "id": "wan-2.6-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "1080p",
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": true,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "high_resolution",
          "audio",
          "long_duration",
          "open_source",
          "venice_recommendations"
        ],
        "name": "Wan 2.6",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.55
      }
    },
    {
      "created": 1768824000,
      "id": "wan-2.6-flash-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "1080p",
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": true,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "high_resolution",
          "audio",
          "long_duration",
          "open_source",
          "venice_recommendations"
        ],
        "name": "Wan 2.6 Flash",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.28
      }
    },
    {
      "created": 1765843200,
      "id": "wan-2.6-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "1080p",
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": true,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "high_resolution",
          "audio",
          "long_duration",
          "open_source",
          "venice_recommendations"
        ],
        "name": "Wan 2.6",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.55
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.5-preview-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "1080p",
            "720p",
            "480p"
          ],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": true,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "high_resolution",
          "audio",
          "open_source",
          "venice_recommendations"
        ],
        "name": "Wan 2.5 Preview",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.28
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.5-preview-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "1080p",
            "720p",
            "480p"
          ],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": true,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "high_resolution",
          "audio",
          "open_source",
          "venice_recommendations"
        ],
        "name": "Wan 2.5 Preview",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.28
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.2-a14b-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p",
            "580p",
            "480p"
          ],
          "durations": [
            "5s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "open_source"
        ],
        "name": "Wan 2.2 A14B",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.06
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.1-pro-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [],
          "durations": [
            "6s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "open_source"
        ],
        "name": "Wan 2.1 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.88
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-fast-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s",
            "12s",
            "14s",
            "16s",
            "18s",
            "20s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "long_duration",
          "open_source"
        ],
        "name": "LTX Video 2.0 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.06
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-fast-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s",
            "12s",
            "14s",
            "16s",
            "18s",
            "20s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "long_duration",
          "open_source",
          "fast"
        ],
        "name": "LTX Video 2.0 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.06
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-full-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "open_source"
        ],
        "name": "LTX Video 2.0 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.58
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-full-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "open_source"
        ],
        "name": "LTX Video 2.0 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.58
      }
    },
    {
      "created": 1767830400,
      "id": "ltx-2-19b-full-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "8s",
            "10s",
            "15s",
            "18s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "audio",
          "long_duration",
          "open_source"
        ],
        "name": "LTX Video 2.0 19B",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.23
      }
    },
    {
      "created": 1767830400,
      "id": "ltx-2-19b-full-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "8s",
            "10s",
            "15s",
            "18s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "audio",
          "long_duration",
          "open_source"
        ],
        "name": "LTX Video 2.0 19B",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.23
      }
    },
    {
      "created": 1767830400,
      "id": "ltx-2-19b-distilled-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "8s",
            "10s",
            "15s",
            "18s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "audio",
          "long_duration",
          "open_source",
          "fast"
        ],
        "name": "LTX Video 2.0 19B Distilled",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.1
      }
    },
    {
      "created": 1767830400,
      "id": "ltx-2-19b-distilled-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "8s",
            "10s",
            "15s",
            "18s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "audio",
          "long_duration",
          "open_source"
        ],
        "name": "LTX Video 2.0 19B Distilled",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.1
      }
    },
    {
      "created": 1758825748,
      "id": "ovi-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [],
          "durations": [
            "5s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "audio",
          "open_source"
        ],
        "name": "Ovi",
        "modelSource": "https://huggingface.co/chetwinlow1/Ovi",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.22
      }
    },
    {
      "created": 1733186476,
      "id": "kling-2.6-pro-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "cinematic",
          "audio",
          "photorealistic"
        ],
        "name": "Kling 2.6 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.77
      }
    },
    {
      "created": 1733186476,
      "id": "kling-2.6-pro-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "cinematic",
          "audio",
          "photorealistic"
        ],
        "name": "Kling 2.6 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.77
      }
    },
    {
      "created": 1758825748,
      "id": "kling-2.5-turbo-pro-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "cinematic",
          "photorealistic"
        ],
        "name": "Kling 2.5 Turbo Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.39
      }
    },
    {
      "created": 1758825748,
      "id": "kling-2.5-turbo-pro-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "cinematic",
          "photorealistic"
        ],
        "name": "Kling 2.5 Turbo Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.39
      }
    },
    {
      "created": 1770076800,
      "id": "kling-o3-pro-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [],
          "durations": [
            "3s",
            "5s",
            "8s",
            "10s",
            "13s",
            "15s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "cinematic",
          "audio",
          "photorealistic",
          "long_duration",
          "venice_recommendations"
        ],
        "name": "Kling O3 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.06
      }
    },
    {
      "created": 1770076800,
      "id": "kling-o3-pro-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [],
          "durations": [
            "3s",
            "5s",
            "8s",
            "10s",
            "13s",
            "15s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "cinematic",
          "audio",
          "photorealistic",
          "long_duration",
          "venice_recommendations"
        ],
        "name": "Kling O3 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.06
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-distilled-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "long_duration",
          "open_source"
        ],
        "name": "Longcat Distilled",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.09
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-distilled-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "long_duration",
          "open_source"
        ],
        "name": "Longcat Distilled",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.09
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "long_duration",
          "open_source"
        ],
        "name": "Longcat Full Quality",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.25
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "uncensored",
          "long_duration",
          "open_source"
        ],
        "name": "Longcat Full Quality",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.25
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-fast-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Veo 3 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.44
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-fast-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [],
          "durations": [
            "8s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "audio",
          "cinematic",
          "photorealistic",
          "fast"
        ],
        "name": "Veo 3 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.88
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-full-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "cinematic",
          "photorealistic",
          "fast"
        ],
        "name": "Veo 3 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.88
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-full-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [],
          "durations": [
            "8s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "audio",
          "cinematic",
          "photorealistic",
          "fast"
        ],
        "name": "Veo 3 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.76
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-fast-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p",
            "4k"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Veo 3.1 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.66
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-fast-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "720p",
            "1080p",
            "4k"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Veo 3.1 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.32
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-full-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p",
            "4k"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Veo 3.1 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.76
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-full-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "720p",
            "1080p",
            "4k"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "ultra_high_resolution",
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Veo 3.1 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 3.52
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Sora 2",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.44
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-pro-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Sora 2 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 2.22
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Sora 2",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.44
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-pro-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "cinematic",
          "photorealistic"
        ],
        "name": "Sora 2 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 2.22
      }
    },
    {
      "created": 1769472000,
      "id": "pixverse-v5.6-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1",
            "4:3",
            "3:4"
          ],
          "resolutions": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "durations": [
            "5s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "cinematic",
          "fast"
        ],
        "name": "PixVerse v5.6",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.9
      }
    },
    {
      "created": 1769472000,
      "id": "pixverse-v5.6-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "durations": [
            "5s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "cinematic"
        ],
        "name": "PixVerse v5.6",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.9
      }
    },
    {
      "created": 1769472000,
      "id": "pixverse-v5.6-transition",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1",
            "4:3",
            "3:4"
          ],
          "resolutions": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "durations": [
            "5s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "cinematic"
        ],
        "name": "PixVerse v5.6 Transition",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.9
      }
    },
    {
      "created": 1769817600,
      "id": "vidu-q3-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "1:1"
          ],
          "resolutions": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "durations": [
            "3s",
            "5s",
            "8s",
            "10s",
            "12s",
            "14s",
            "16s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "long_duration",
          "cinematic",
          "venice_recommendations"
        ],
        "name": "Vidu Q3",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.58
      }
    },
    {
      "created": 1769817600,
      "id": "vidu-q3-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "durations": [
            "3s",
            "5s",
            "8s",
            "10s",
            "12s",
            "14s",
            "16s"
          ],
          "audio": true,
          "audio_configurable": true,
          "audio_input": false,
          "video_input": false
        },
        "model_sets": [
          "high_resolution",
          "audio",
          "long_duration",
          "cinematic",
          "venice_recommendations"
        ],
        "name": "Vidu Q3",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.58
      }
    }
  ],
  "other": [
    {
      "created": 1741924661,
      "id": "text-embedding-bge-m3",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.15,
            "diem": 0.15
          },
          "output": {
            "usd": 0.6,
            "diem": 0.6
          }
        },
        "name": "BGE-M3",
        "modelSource": "https://huggingface.co/BAAI/bge-m3",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "embedding"
    },
    {
      "created": 1742418046,
      "id": "tts-kokoro",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 3.5,
            "diem": 3.5
          }
        },
        "voices": [
          "af_alloy",
          "af_aoede",
          "af_bella",
          "af_heart",
          "af_jadzia",
          "af_jessica",
          "af_kore",
          "af_nicole",
          "af_nova",
          "af_river",
          "af_sarah",
          "af_sky",
          "am_adam",
          "am_echo",
          "am_eric",
          "am_fenrir",
          "am_liam",
          "am_michael",
          "am_onyx",
          "am_puck",
          "am_santa",
          "bf_alice",
          "bf_emma",
          "bf_lily",
          "bm_daniel",
          "bm_fable",
          "bm_george",
          "bm_lewis",
          "ef_dora",
          "em_alex",
          "em_santa",
          "ff_siwis",
          "hf_alpha",
          "hf_beta",
          "hm_omega",
          "hm_psi",
          "if_sara",
          "im_nicola",
          "jf_alpha",
          "jf_gongitsune",
          "jf_nezumi",
          "jf_tebukuro",
          "jm_kumo",
          "pf_dora",
          "pm_alex",
          "pm_santa",
          "zf_xiaobei",
          "zf_xiaoni",
          "zf_xiaoxiao",
          "zf_xiaoyi",
          "zm_yunjian",
          "zm_yunxi",
          "zm_yunxia",
          "zm_yunyang"
        ],
        "name": "Kokoro Text to Speech",
        "modelSource": "https://huggingface.co/hexgrad/Kokoro-82M",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "tts"
    },
    {
      "created": 1744453050,
      "id": "upscaler",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "name": "Upscaler",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "upscale"
    },
    {
      "created": 1756157864,
      "id": "qwen-edit",
      "model_spec": {
        "pricing": {
          "inpaint": {
            "usd": 0.04,
            "diem": 0.04
          }
        },
        "constraints": {
          "aspectRatios": [
            "auto",
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "promptCharacterLimit": 1500,
          "combineImages": true
        },
        "name": "Qwen Edit 2511",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "inpaint"
    },
    {
      "created": 1767571200,
      "id": "flux-2-max-edit",
      "model_spec": {
        "pricing": {
          "inpaint": {
            "usd": 0.09,
            "diem": 0.09
          }
        },
        "constraints": {
          "aspectRatios": [
            "auto",
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "promptCharacterLimit": 3000,
          "combineImages": true
        },
        "name": "Flux 2 Max",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "inpaint"
    },
    {
      "created": 1767555000,
      "id": "gpt-image-1-5-edit",
      "model_spec": {
        "pricing": {
          "inpaint": {
            "usd": 0.23,
            "diem": 0.23
          }
        },
        "constraints": {
          "aspectRatios": [
            "auto",
            "1:1",
            "3:2",
            "2:3"
          ],
          "promptCharacterLimit": 32768,
          "combineImages": true
        },
        "name": "GPT Image 1.5",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "inpaint"
    },
    {
      "created": 1772064000,
      "id": "nano-banana-2-edit",
      "model_spec": {
        "pricing": {
          "inpaint": {
            "usd": 0.08,
            "diem": 0.08
          }
        },
        "constraints": {
          "aspectRatios": [
            "auto",
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "promptCharacterLimit": 32768,
          "combineImages": true
        },
        "name": "Nano Banana 2",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "inpaint"
    },
    {
      "created": 1765584000,
      "id": "nano-banana-pro-edit",
      "model_spec": {
        "pricing": {
          "inpaint": {
            "usd": 0.18,
            "diem": 0.18
          }
        },
        "constraints": {
          "aspectRatios": [
            "auto",
            "1:1",
            "3:2",
            "16:9",
            "21:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "promptCharacterLimit": 32768,
          "combineImages": true
        },
        "name": "Nano Banana Pro",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "inpaint"
    },
    {
      "created": 1767484800,
      "id": "seedream-v4-edit",
      "model_spec": {
        "pricing": {
          "inpaint": {
            "usd": 0.05,
            "diem": 0.05
          }
        },
        "constraints": {
          "aspectRatios": [
            "auto",
            "1:1",
            "3:2",
            "16:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "promptCharacterLimit": 10000,
          "combineImages": true
        },
        "name": "SeedreamV4.5",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "inpaint"
    },
    {
      "created": 1771804800,
      "id": "seedream-v5-lite-edit",
      "model_spec": {
        "pricing": {
          "inpaint": {
            "usd": 0.05,
            "diem": 0.05
          }
        },
        "constraints": {
          "aspectRatios": [
            "auto",
            "1:1",
            "3:2",
            "16:9",
            "9:16",
            "2:3",
            "3:4",
            "4:5"
          ],
          "promptCharacterLimit": 10000,
          "combineImages": true
        },
        "name": "SeedreamV5 Lite",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "inpaint"
    },
    {
      "created": 1760136444,
      "id": "nvidia/parakeet-tdt-0.6b-v3",
      "model_spec": {
        "pricing": {
          "per_audio_second": {
            "usd": 0.0001,
            "diem": 0.0001
          }
        },
        "name": "Parakeet ASR",
        "modelSource": "https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "asr"
    },
    {
      "created": 1736899200,
      "id": "openai/whisper-large-v3",
      "model_spec": {
        "pricing": {
          "per_audio_second": {
            "usd": 0.0001,
            "diem": 0.0001
          }
        },
        "name": "Whisper Large V3",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "asr"
    }
  ]
};
    </script>

    <script>
        let currentTab = 'text';
        let sortKey = 'price_avg';
        let sortAsc = true;

        // Active filters state
        let activeFilters = new Set();

        const get = (obj, path, def = null) => {
            try {
                const val = path.split('.').reduce((acc, part) => acc[part], obj);
                return (val !== undefined && val !== null) ? val : def;
            } catch (e) {
                return def;
            }
        };

        const getMinContext = () => {
            const el = document.getElementById('minContext');
            const val = el ? parseInt(el.value, 10) : 0;
            return Number.isFinite(val) ? val : 0;
        };

        const getMaxAvgPrice = () => {
            const el = document.getElementById('maxAvgPrice');
            if (!el) return null;
            const val = parseFloat(el.value);
            return Number.isFinite(val) ? val : null;
        };


        // --- Configuration ---

        const getProvider = (m) => {
            const id = m.id.toLowerCase();
            const src = get(m, 'model_spec.modelSource', '').toLowerCase();
            const name = get(m, 'model_spec.name', '').toLowerCase();
            
            if (id.includes('llama') || src.includes('meta-llama')) return 'meta';
            if (id.includes('gemma') || src.includes('google/gemma')) return 'google';
            if (id.includes('gemini') || src.includes('deepmind')) return 'google';
            if (id.includes('gpt') || src.includes('openai')) return 'openai';
            if (id.includes('claude') || src.includes('anthropic')) return 'anthropic';
            if (id.includes('deepseek')) return 'deepseek';
            if (id.includes('mistral')) return 'mistral';
            if (id.includes('qwen')) return 'qwen';
            if (id.includes('glm') || src.includes('zai-org')) return 'zai-org';
            if (id.includes('kimi') || src.includes('moonshot')) return 'moonshot';
            if (id.includes('grok') || src.includes('xai')) return 'xai';
            if (id.includes('hermes') || src.includes('nous')) return 'nous';
            if (id.includes('sd') || id.includes('flux') || src.includes('stability')) return 'stability';
            if (id.startsWith('venice-')) return 'venice';
            return 'other';
        };

        const filters = {
            text: [
                { group: 'Capabilities', items: [
                    { id: 'supportsReasoning', label: 'üß† Reasoning' },
                    { id: 'supportsVision', label: 'üëÅÔ∏è Vision' },
                    { id: 'supportsFunctionCalling', label: 'üõ†Ô∏è Func Call' },
                    { id: 'optimizedForCode', label: 'üíª Code' },
                    { id: 'hasCache', label: '‚ö° Caching' },
                    { id: 'is_beta', label: 'üß™ Beta' },
                    { id: 'trait_most_uncensored', label: 'üîì Uncensored' },
                    { id: 'trait_fastest', label: '‚ö° Fastest' }
                ]},
                { group: 'Privacy', items: [
                    { id: 'is_private', label: 'üîí Private' },
                    { id: 'is_anonymized', label: 'üïµÔ∏è Anonymized' }
                ]},
                { group: 'Providers', items: [
                    { id: 'prov_meta', label: 'Meta' },
                    { id: 'prov_google', label: 'Google' },
                    { id: 'prov_openai', label: 'OpenAI' },
                    { id: 'prov_anthropic', label: 'Anthropic' },
                    { id: 'prov_deepseek', label: 'DeepSeek' },
                    { id: 'prov_qwen', label: 'Qwen' }
                ]}
            ],
            image: [
                { group: 'Capabilities', items: [
                    { id: 'hasUpscale', label: 'üîç Upscale' }
                ]},
                { group: 'Privacy', items: [
                    { id: 'is_private', label: 'üîí Private' },
                    { id: 'is_anonymized', label: 'üïµÔ∏è Anonymized' }
                ]},
                { group: 'Providers', items: [
                    { id: 'prov_stability', label: 'Stability' },
                    { id: 'prov_qwen', label: 'Qwen' }
                ]}
            ],
            video: [
                { group: 'Type', items: [
                    { id: 'text-to-video', label: 'üìù T2V' },
                    { id: 'image-to-video', label: 'üñºÔ∏è I2V' }
                ]},
                { group: 'Capabilities', items: [
                    { id: 'audio', label: 'üéµ Audio' }
                ]},
                { group: 'Privacy', items: [
                    { id: 'is_private', label: 'üîí Private' },
                    { id: 'is_anonymized', label: 'üïµÔ∏è Anonymized' }
                ]}
            ]
        };

        const headers = {
            text: [
                { key: 'name', label: 'Model', class: 'col-model' },
                { key: 'price_combined', label: 'Pricing ($/1M) <div class="price-header-sort"><span id="sort_in">In</span> | <span id="sort_avg">Avg</span> | <span id="sort_out">Out</span></div>', class: 'col-combined-price' },
                { key: 'cache_price', label: 'Cache ($/1M)', class: 'col-price' },
                { key: 'context', label: 'Context', class: 'col-ctx' },
                { key: 'caps', label: 'Capabilities', class: 'col-caps' }
            ],
            image: [
                { key: 'name', label: 'Model', class: 'col-model' },
                { key: 'price_gen', label: 'Generation Price', class: 'col-price' },
                { key: 'steps', label: 'Steps', class: '' },
                { key: 'upscale', label: 'Upscale', class: '' }
            ],
            video: [
                { key: 'name', label: 'Model', class: 'col-model' },
                { key: 'price_video', label: 'Pricing', class: 'col-price' },
                { key: 'res', label: 'Resolutions', class: '' },
                { key: 'audio', label: 'Audio', class: '' }
            ]
        };

        const strategies = {
            text: {
                getPrice: (m) => (get(m, 'model_spec.pricing.input.usd', 0) + get(m, 'model_spec.pricing.output.usd', 0)) / 2,
                getCachePrice: (m) => get(m, 'model_spec.pricing.cache_input.usd', null),
                renderPrice: (m, max) => {
                    const input = get(m, 'model_spec.pricing.input.usd', 0);
                    const output = get(m, 'model_spec.pricing.output.usd', 0);
                    const avg = (input + output) / 2;
                    const pct = max > 0 ? (avg / max) * 100 : 0;


                    return `
                        <div class="price-bridge" title="Avg: $${avg.toFixed(3)}/1M tokens">
                            <div class="price-bridge-top">
                                <div class="price-value-group">
                                    <span class="price-value-num">$${input}</span>
                                    <span class="price-value-label">Input</span>
                                </div>
                                <div class="price-bridge-avg-info">
                                    Avg $${avg.toFixed(2)}
                                </div>
                                <div class="price-value-group" style="text-align: right;">
                                    <span class="price-value-num">$${output}</span>
                                    <span class="price-value-label">Output</span>
                                </div>
                            </div>
                            <div class="rel-bar-container">
                                <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                            </div>
                        </div>
                    `;
                },
                renderCachePrice: (m, maxCache) => {
                    const cache = get(m, 'model_spec.pricing.cache_input.usd');
                    if (cache === undefined || cache === null) return `<span style="color:var(--text-muted);opacity:0.5">‚Äî</span>`;

                    const pct = maxCache > 0 ? (cache / maxCache) * 100 : 0;
                    return `
                    <div class="price-cell">
                        <div class="price-val">$${cache}</div>
                        <div class="rel-bar-container" title="Relative Cache Cost: ${Math.round(pct)}%">
                            <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                        </div>
                    </div>
                `;
                },
                renderCaps: (m) => {
                    const c = get(m, 'model_spec.capabilities', {});
                    const pricing = get(m, 'model_spec.pricing', {});
                    const caps = [
                        { k: 'supportsReasoning', label: 'Reasoning', cls: 'feat-reasoning' },
                        { k: 'supportsVision', label: 'Vision', cls: 'feat-vision' },
                        { k: 'supportsFunctionCalling', label: 'Func Call', cls: 'feat-func' },
                        { k: 'optimizedForCode', label: 'Code', cls: 'feat-code' },
                        { k: 'supportsWebSearch', label: 'Web Search', cls: 'feat-search' },
                        { k: 'supportsAudioInput', label: 'Audio In', cls: 'feat-logprobs' },
                        { k: 'supportsVideoInput', label: 'Video In', cls: 'feat-logprobs' },
                        { k: 'supportsLogProbs', label: 'Logprobs', cls: 'feat-logprobs' },
                        { k: 'supportsResponseSchema', label: 'JSON Mode', cls: 'feat-json' }
                    ];

                    let badges = caps
                        .filter(cap => c[cap.k] === true)
                        .map(cap => `<span class="feature-badge ${cap.cls}">${cap.label}</span>`);

                    if (pricing.cache_input) {
                        badges.push(`<span class="feature-badge feat-cache">Cache</span>`);
                    }

                    if (badges.length === 0) return '<span style="color:var(--text-muted);opacity:0.5">‚Äî</span>';
                    return `<div class="feature-tags">${badges.join('')}</div>`;
                },
                renderCtx: (m) => {
                    const t = get(m, 'model_spec.availableContextTokens', 0);
                    return Math.round(t / 1024) + 'k';
                },
                checkFilter: (m, fid) => {
                    if (fid === 'hasCache') return get(m, 'model_spec.pricing.cache_input.usd') !== null;
                    if (fid === 'is_beta') return get(m, 'model_spec.betaModel') === true;
                    if (fid === 'is_private') return (get(m, 'model_spec.privacy') || m.privacy) === 'private';
                    if (fid === 'is_anonymized') return (get(m, 'model_spec.privacy') || m.privacy) === 'anonymized';
                    if (fid.startsWith('trait_')) {
                        const trait = fid.replace('trait_', '');
                        return (get(m, 'model_spec.traits') || []).includes(trait);
                    }
                    if (fid.startsWith('prov_')) {
                        const prov = fid.replace('prov_', '');
                        return getProvider(m) === prov;
                    }
                    return get(m, 'model_spec.capabilities.' + fid) === true;
                }
            },
            image: {
                getPrice: (m) => get(m, 'model_spec.pricing.generation.usd', 0),
                renderPrice: (m, max) => {
                    const p = get(m, 'model_spec.pricing.generation.usd', 0);
                    const pct = max > 0 ? (p / max) * 100 : 0;
                    return `
                    <div class="price-cell">
                        <div class="price-val">$${p} / img</div>
                        <div class="rel-bar-container">
                            <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                        </div>
                    </div>
                `;
                },
                renderCaps: (m) => '',
                checkFilter: (m, fid) => {
                    if (fid === 'hasUpscale') return !!get(m, 'model_spec.pricing.upscale.2x.usd');
                    if (fid === 'is_private') return (get(m, 'model_spec.privacy') || m.privacy) === 'private';
                    if (fid === 'is_anonymized') return (get(m, 'model_spec.privacy') || m.privacy) === 'anonymized';
                    if (fid.startsWith('prov_')) {
                        const prov = fid.replace('prov_', '');
                        return getProvider(m) === prov;
                    }
                    return false;
                }
            },
            video: {
                getPrice: (m) => get(m, 'pricing.base_price_usd', 0),
                renderPrice: (m, max) => {
                    const p = get(m, 'pricing.base_price_usd');
                    if (p === undefined) return `<span class="tag">Dynamic</span>`;

                    const pct = max > 0 ? (p / max) * 100 : 0;
                    return `
                    <div class="price-cell">
                        <div class="price-val">$${p.toFixed(2)}</div>
                        <div class="rel-bar-container">
                            <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                        </div>
                    </div>
                `;
                },
                renderCaps: (m) => '',
                checkFilter: (m, fid) => {
                    if (fid === 'audio') return get(m, 'model_spec.constraints.audio', false);
                    if (fid === 'text-to-video') return get(m, 'model_spec.constraints.model_type') === 'text-to-video';
                    if (fid === 'image-to-video') return get(m, 'model_spec.constraints.model_type') === 'image-to-video';
                    if (fid === '1080p') return (get(m, 'model_spec.constraints.resolutions') || []).includes('1080p');
                    if (fid === 'is_private') return (get(m, 'model_spec.privacy') || m.privacy) === 'private';
                    if (fid === 'is_anonymized') return (get(m, 'model_spec.privacy') || m.privacy) === 'anonymized';
                    if (fid.startsWith('prov_')) {
                        const prov = fid.replace('prov_', '');
                        return getProvider(m) === prov;
                    }
                    return false;
                }
            }
        };

        function getBarColor(p) {
            if (p < 33) return 'bar-low';
            if (p < 66) return 'bar-med';
            return 'bar-high';
        }

        // --- Main Logic ---

        function switchTab(t) {
            currentTab = t;
            activeFilters.clear(); // Clear filters when switching tabs

            // Reset sort defaults
            if (t === 'text') sortKey = 'price_avg';
            else if (t === 'image') sortKey = 'price_gen';
            else if (t === 'video') sortKey = 'price_video';

            sortAsc = true;

            document.querySelectorAll('.tab-btn').forEach(b => b.classList.toggle('active', b.textContent.toLowerCase() === t));

            renderFilters();
            updateRangeControlsVisibility();
            renderTable();
        }

        function toggleFilter(fid) {
            if (activeFilters.has(fid)) {
                activeFilters.delete(fid);
            } else {
                // Exclusivity logic
                if (fid === 'is_private') activeFilters.delete('is_anonymized');
                if (fid === 'is_anonymized') activeFilters.delete('is_private');
                
                activeFilters.add(fid);
            }
            renderFilters();
            renderTable();
        }

        function clearFilters() {
            activeFilters.clear();
            renderFilters();
            renderTable();
        }

        function renderFilters() {
            const bar = document.getElementById('filterBar');
            const groups = filters[currentTab] || [];

            if (groups.length === 0) {
                bar.style.display = 'none';
                bar.innerHTML = '';
                return;
            }

            bar.style.display = 'flex';
            bar.innerHTML = groups.map(g => {
                // If the group is 'Privacy', render as a Segmented Control
                if (g.group === 'Privacy') {
                    return `
                        <div class="filter-group">
                            <div class="filter-group-label">${g.group}</div>
                            <div class="filter-segment">
                                ${g.items.map(f => `
                                    <div class="filter-segment-item ${activeFilters.has(f.id) ? 'active' : ''}" 
                                         onclick="toggleFilter('${f.id}')">
                                        ${f.label}
                                    </div>
                                `).join('')}
                            </div>
                        </div>
                    `;
                }

                // Default rendering for other groups
                return `
                    <div class="filter-group">
                        <div class="filter-group-label">${g.group}</div>
                        ${g.items.map(f => `
                            <label class="filter-item">
                                <input type="checkbox" onchange="toggleFilter('${f.id}')" ${activeFilters.has(f.id) ? 'checked' : ''}>
                                <span>${f.label}</span>
                            </label>
                        `).join('')}
                    </div>
                `;
            }).join('');
        }

        function updateRangeControlsVisibility() {
            const range = document.getElementById('rangeControls');
            if (!range) return;
            range.style.display = currentTab === 'text' ? 'flex' : 'none';
        }

        function setCheapestSort() {
            if (currentTab !== 'text') return;
            sortKey = 'price_avg';
            sortAsc = true;
            renderTable();
        }

        function setNewestSort() {
            sortKey = 'created';
            sortAsc = false;
            renderTable();
        }

        function setContextPriceSort() {
            if (currentTab !== 'text') return;
            sortKey = 'context_price';
            sortAsc = true;
            renderTable();
        }

        function handleSort(key) {
            // Price rotation for Text Tab
            if (key === 'price_combined' && currentTab === 'text') {
                if (sortKey === 'price_avg') sortKey = 'price_input';
                else if (sortKey === 'price_input') sortKey = 'price_output';
                else sortKey = 'price_avg';
                sortAsc = true;
            }
            // Fallback for Generic price sorting (Image/Video)
            else if (key === 'price_gen' || key === 'price_video' || key === 'price_combined') {
                sortKey = 'price_avg';
                sortAsc = !sortAsc;
            }
            else {
                if (sortKey === key) sortAsc = !sortAsc;
                else {
                    sortKey = key;
                    sortAsc = true;
                }
            }
            renderTable();
        }

        function renderTable() {
            const thead = document.getElementById('tableHead');
            const tbody = document.getElementById('tableBody');
            const cols = headers[currentTab];
            const models = window.veniceModels[currentTab] || [];
            const term = document.getElementById('searchInput').value.toLowerCase();
            const minContext = currentTab === 'text' ? getMinContext() : 0;
            const maxAvgPrice = currentTab === 'text' ? getMaxAvgPrice() : null;

            // 1. Render Headers
            thead.innerHTML = `<tr>
            ${cols.map(c => {
                let label = c.label;
                const isPriceCombined = c.key === 'price_combined';
                if (isPriceCombined) {
                    const activeIn = sortKey === 'price_input' ? 'active-sort' : '';
                    const activeAvg = sortKey === 'price_avg' ? 'active-sort' : '';
                    const activeOut = sortKey === 'price_output' ? 'active-sort' : '';
                    label = `Pricing ($/1M) <div class="price-header-sort">
                        <span class="${activeIn}" onclick="event.stopPropagation(); handleSort('price_input')">In</span> | 
                        <span class="${activeAvg}" onclick="event.stopPropagation(); handleSort('price_avg')">Avg</span> | 
                        <span class="${activeOut}" onclick="event.stopPropagation(); handleSort('price_output')">Out</span>
                    </div>`;
                }
                const isActive = sortKey === c.key || (isPriceCombined && sortKey.startsWith('price_'));
                const icon = isActive ? (sortAsc ? '‚ñ≤' : '‚ñº') : '';
                return `<th class="${c.class}" onclick="handleSort('${c.key}')">${label} ${icon}</th>`;
            }).join('')}
        </tr>`;

            // 2. Filter
            let data = models.filter(m => {
                // Text Search
                const n = get(m, 'model_spec.name', '').toLowerCase();
                const i = m.id.toLowerCase();
                const s = get(m, 'model_spec.modelSource', '').toLowerCase();
                const d = get(m, 'model_spec.description', '').toLowerCase();
                if (!(n.includes(term) || i.includes(term) || s.includes(term) || d.includes(term))) return false;

                if (currentTab === 'text') {
                    const ctx = get(m, 'model_spec.availableContextTokens', 0);
                    if (ctx < minContext) return false;
                    const input = get(m, 'model_spec.pricing.input.usd', 0);
                    const output = get(m, 'model_spec.pricing.output.usd', 0);
                    const avg = (input + output) / 2;
                    if (maxAvgPrice !== null && avg > maxAvgPrice) return false;
                }

                // Capability Filters
                const strat = strategies[currentTab];
                for (let fid of activeFilters) {
                    if (!strat.checkFilter(m, fid)) return false;
                }

                return true;
            });

            // Update visible count in UI
            const countInfo = document.querySelector('.meta');
            if (countInfo) {
                const baseText = countInfo.innerHTML.split(' | ')[0];
                countInfo.innerHTML = `${baseText} | <strong>Showing ${data.length} models</strong>`;
            }

            // 3. Prepare Sort Data & Max Price
            const currentStrat = strategies[currentTab];
            const maxPrice = Math.max(0, ...data.map(m => currentStrat.getPrice(m)));
            const maxCache = (currentTab === 'text') ? Math.max(0.00001, ...data.map(m => currentStrat.getCachePrice(m) || 0)) : 0;

            data.forEach(m => {
                if (currentTab === 'text') {
                    m._sort_price_input = get(m, 'model_spec.pricing.input.usd', 0);
                    m._sort_price_output = get(m, 'model_spec.pricing.output.usd', 0);
                    m._sort_price_avg = (m._sort_price_input + m._sort_price_output) / 2;
                } else if (currentTab === 'image') {
                    m._sort_price_avg = get(m, 'model_spec.pricing.generation.usd', 0);
                } else if (currentTab === 'video') {
                    m._sort_price_avg = get(m, 'pricing.base_price_usd', 0);
                }
                m._sort_cache = (currentTab === 'text') ? (currentStrat.getCachePrice(m) || 0) : 0;
                m._sort_name = get(m, 'model_spec.name', '');
                m._sort_context = get(m, 'model_spec.availableContextTokens', 0);
                m._sort_created = m.created || 0;
            });

            // 4. Sort
            data.sort((a, b) => {
                if (sortKey === 'context_price') {
                    if (a._sort_context !== b._sort_context) return b._sort_context - a._sort_context;
                    return a._sort_price_avg - b._sort_price_avg;
                }
                let valA, valB;
                if (sortKey === 'price_input') { valA = a._sort_price_input; valB = b._sort_price_input; }
                else if (sortKey === 'price_output') { valA = a._sort_price_output; valB = b._sort_price_output; }
                else if (sortKey === 'price_avg') { valA = a._sort_price_avg; valB = b._sort_price_avg; }
                else if (sortKey === 'cache_price') { valA = a._sort_cache; valB = b._sort_cache; }
                else if (sortKey === 'name') { valA = a._sort_name; valB = b._sort_name; }
                else if (sortKey === 'created') { valA = a._sort_created; valB = b._sort_created; }
                else if (sortKey === 'context') { valA = a._sort_context; valB = b._sort_context; }
                else { valA = a._sort_price_avg; valB = b._sort_price_avg; }

                if (valA < valB) return sortAsc ? -1 : 1;
                if (valA > valB) return sortAsc ? 1 : -1;
                return 0;
            });

            // 5. Render Rows
            tbody.innerHTML = data.map(m => {
                const spec = m.model_spec || {};
                const created = m.created || 0;
                const isNew = created > (Date.now() / 1000 - 30 * 24 * 60 * 60); // Last 30 days
                const isBeta = spec.betaModel === true;
                const privacy = spec.privacy || m.privacy || 'N/A';
                const privacyClass = privacy === 'private' ? 'privacy-private' : 'privacy-anonymized';

                // Common Cells
                const q = get(m, 'model_spec.capabilities.quantization');
                const showQ = q && q !== 'not-available';
                const nameCell = `
                    <div>
                        <div style="display: flex; align-items: center; gap: 8px;">
                            <a href="${spec.modelSource || '#'}" target="_blank" class="model-name">${spec.name || m.id}</a>
                            ${isNew ? '<span class="new-badge">NEW</span>' : ''}
                            ${isBeta ? '<span class="beta-badge">BETA</span>' : ''}
                            <span class="privacy-badge ${privacyClass}">${privacy}</span>
                        </div>
                        <div class="model-id">
                            ${m.id} 
                            ${showQ ? `<span class="cap-badge" style="opacity:1; background:var(--bar-bg); border:none;">${q}</span>` : ''}
                        </div> 
                        ${spec.description ? `<div class="model-description" title="Click to expand" onclick="this.classList.toggle('expanded')">${spec.description}</div>` : ''}
                        <div class="tag-row">${(spec.traits || []).map(t => `<span class="cap-badge">${t}</span>`).join('')}</div>
                    </div>
                `;

                // Specific Cells
                if (currentTab === 'text') {
                    return `
                        <tr>
                            <td>${nameCell}</td>
                            <td>${currentStrat.renderPrice(m, maxPrice)}</td>
                            <td>${currentStrat.renderCachePrice(m, maxCache)}</td>
                            <td>${currentStrat.renderCtx(m)}</td>
                            <td>${currentStrat.renderCaps(m)}</td>
                        </tr>
                    `;
                } else if (currentTab === 'image') {
                    const steps = get(m, 'model_spec.constraints.steps.max', 'N/A');
                    const upscale = get(m, 'model_spec.pricing.upscale.2x.usd') ? `$${get(m, 'model_spec.pricing.upscale.2x.usd')} (2x)` : '‚Äî';
                    return `
                        <tr>
                            <td>${nameCell}</td>
                            <td>${currentStrat.renderPrice(m, maxPrice)}</td>
                            <td>${steps}</td>
                            <td>${upscale}</td>
                        </tr>
                    `;
                } else if (currentTab === 'video') {
                    const res = (get(m, 'model_spec.constraints.resolutions') || []).join(', ');
                    const audio = get(m, 'model_spec.constraints.audio') ? '‚úÖ Yes' : '‚ùå No';
                    return `
                        <tr>
                            <td>${nameCell}</td>
                            <td>${currentStrat.renderPrice(m, maxPrice)}</td>
                            <td>${res}</td>
                            <td>${audio}</td>
                        </tr>
                    `;
                }
                return '';
            }).join('');
        }

        // Initialize
        updateRangeControlsVisibility();
        renderFilters();
        renderTable();

    </script>
</body>

</html>